Here's a custom interview guide for Ritesh Kumar Paryani, structured around his most relevant experience, technical stack, governance exposure, and independence. The focus is on assessing his fit for a senior technical data science role, especially with cloud-based ML systems, compliance-heavy environments, and LLM-based automation.


---

ðŸ”¹ INTRODUCTORY QUESTIONS (Experience Overview)

Recent Work at Amazon:

1. Can you walk us through the BI platform youâ€™ve built at Amazon Ads? What were the biggest challenges in scaling and automating analytics across such a large user base?


2. You mentioned integrating LLM-based self-serve toolsâ€”whatâ€™s an example of a real business problem this helped solve?


3. You delivered $500K in platform cost efficiencyâ€”what were the technical or architectural decisions that contributed to this?


4. How did you collaborate across product, engineering, and data science in your role?



Barclays Experience:

5. At Barclays, you worked across compliance, fraud, and risk analytics. What was the most complex or sensitive use case you worked on?


6. Can you share how you built and maintained compliance models? How did you validate and monitor them?




---

ðŸ”¹ TECHNICAL DEEP DIVE

Cloud & AWS:

7. You list AWS Glue, S3, Kinesis, Redshift, EC2, etc. Can you describe a typical ML or BI pipeline youâ€™ve deployed on AWS?


8. Have you used AWS SageMaker for model training or hosting? If so, what was your experience with experiment tracking, pipelines, and model registry?


9. How do you monitor cost and performance trade-offs in cloud-based systems, especially for data-heavy applications?



Big Data, PySpark & ETL:

10. Youâ€™ve worked with Spark and PySpark. How did you use these in the context of building ETL pipelines or preparing training data?


11. Whatâ€™s your approach to optimizing Spark jobs for large-scale feature engineering or batch scoring?


12. Have you handled schema drift or data inconsistencies at scale? How did you manage schema enforcement in Spark or Glue?



ML & AI:

13. You mention experience with fraud detection, CLV, and segmentation. Can you talk about one ML model you took end-to-endâ€”from business framing to monitoring in production?


14. Whatâ€™s your experience with supervised vs unsupervised techniques in fraud or anomaly detection?


15. For LLMs, you mention using multi-modal and toxicity filters. Can you explain how you implemented these and how you evaluated them?




---

ðŸ”¹ GOVERNANCE, COMPLIANCE & RISK

16. Youâ€™ve worked in compliance-heavy domains (GDPR, AML, risk). How do you ensure that your models remain auditable and compliant over time?


17. What processes do you follow to document your models for internal audit or regulatory review?


18. How do you approach data privacy, especially when handling sensitive customer or financial information?




---

ðŸ”¹ INDEPENDENCE & INNOVATION

19. You seem to have taken a proactive role in cross-functional alignment and platform definition. Can you give an example of where you independently proposed and delivered an innovative solution?


20. Imagine you join a team with messy, undocumented pipelines and unclear ownership. What would be your first steps?


21. Youâ€™ve worked across several domainsâ€”how do you adapt your analytics strategy when youâ€™re dealing with a domain thatâ€™s new to you (e.g., advertising vs compliance)?




---

Optional Closing Questions

What tools or techniques are you currently exploring or excited about in the AI/ML space?

If given full ownership of a high-risk model that powers decisions worth millions, how would you design the governance and monitoring system around it?



---

Let me know if you'd like:

Candidate comparison sheet

Interview summary template

Follow-up prompts based on their answers


