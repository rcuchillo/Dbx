{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872adb3b",
   "metadata": {},
   "source": [
    "### üì¶ Load Customer Feature Table with Fraud Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14297174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data = spark.read.format(\"delta\").load(\"dbfs:/tmp/customer_features_table\")\n",
    "\n",
    "# Select features and label\n",
    "features = [c for c in data.columns if c not in (\"customer_id\", \"fraud\", \"amount\")]\n",
    "df = data.select(\"customer_id\", \"fraud\", \"amount\", *features)\n",
    "df = df.dropna()\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063e96",
   "metadata": {},
   "source": [
    "### üìä Visual: Fraud Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3217223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sample = df.sample(False, 0.5, seed=42).toPandas()\n",
    "\n",
    "X = df_sample[features]\n",
    "y = df_sample[\"fraud\"]\n",
    "amounts = df_sample[\"amount\"]\n",
    "\n",
    "y.value_counts().plot(kind='bar', title='Fraud Distribution (0=Genuine, 1=Fraud)', figsize=(5,3))\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bef1f2",
   "metadata": {},
   "source": [
    "### üîÄ Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, amt_train, amt_test = train_test_split(\n",
    "    X, y, amounts, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c4e83",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Define Evaluation Metric at 5% Genuine Decline Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_at_decline(y_true, y_pred_proba, amounts, decline_rate=0.05):\n",
    "    sorted_idx = np.argsort(y_pred_proba)[::-1]\n",
    "    y_true_sorted = y_true.iloc[sorted_idx].reset_index(drop=True)\n",
    "    y_pred_sorted = y_pred_proba[sorted_idx]\n",
    "    amounts_sorted = amounts.iloc[sorted_idx].reset_index(drop=True)\n",
    "\n",
    "    num_to_decline = int(len(y_true) * decline_rate)\n",
    "    y_declined = y_true_sorted.iloc[:num_to_decline]\n",
    "    amounts_declined = amounts_sorted.iloc[:num_to_decline]\n",
    "\n",
    "    fraud_detected = y_declined.sum()\n",
    "    value_detected = amounts_declined[y_declined == 1].sum()\n",
    "    total_fraud = y_true.sum()\n",
    "    total_fraud_value = amounts[y_true == 1].sum()\n",
    "\n",
    "    return {\n",
    "        \"fraud_detection_rate\": fraud_detected / total_fraud if total_fraud else 0,\n",
    "        \"fraud_value_detection_rate\": value_detected / total_fraud_value if total_fraud_value else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7b9e8",
   "metadata": {},
   "source": [
    "### üéØ Hyperparameter Tuning with LightGBM + Hyperopt + MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/fraud_model_lgbm\")\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "        metrics = evaluate_at_decline(y_test, preds, amt_test)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"roc_auc\", auc)\n",
    "        mlflow.log_metric(\"fraud_detection_rate\", metrics[\"fraud_detection_rate\"])\n",
    "        mlflow.log_metric(\"fraud_value_detection_rate\", metrics[\"fraud_value_detection_rate\"])\n",
    "\n",
    "        return {\"loss\": -metrics[\"fraud_value_detection_rate\"], \"status\": STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "    \"num_leaves\": hp.choice(\"num_leaves\", [15, 31, 63]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [4, 6, 8, 10])\n",
    "}\n",
    "\n",
    "best_result = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b34788",
   "metadata": {},
   "source": [
    "### ‚úÖ Train Final Model with Best Hyperparameters and Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e61d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"learning_rate\": best_result[\"learning_rate\"],\n",
    "    \"num_leaves\": [15, 31, 63][best_result[\"num_leaves\"]],\n",
    "    \"max_depth\": [4, 6, 8, 10][best_result[\"max_depth\"]],\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_model\") as run:\n",
    "    final_model = LGBMClassifier(**best_params)\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    preds = final_model.predict_proba(X_test)[:, 1]\n",
    "    metrics = evaluate_at_decline(y_test, preds, amt_test)\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(final_model, artifact_path=\"model\")\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri, \"models:/main.fraud_demo.fraud_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de48e8",
   "metadata": {},
   "source": [
    "### üìà Visual: Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = final_model.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "feat_imp.head(15).plot(kind='barh', title='Top 15 Feature Importances', figsize=(8,6))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0891b7e",
   "metadata": {},
   "source": [
    "### üìò Why MLflow Is a Game Changer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "‚úÖ MLflow Experiment Tracking:\n",
    "- Every model trial is recorded with parameters and performance\n",
    "- Reproducible and comparable across runs\n",
    "\n",
    "‚úÖ Model Registry:\n",
    "- Versioned, staged, production-ready models\n",
    "- Easy promotion (e.g., Staging ‚û°Ô∏è Production)\n",
    "\n",
    "‚úÖ Governance & Reproducibility:\n",
    "- You can always trace back to the exact data, code, and model used\n",
    "- Essential for regulated domains like fraud detection\n",
    "\n",
    "‚úÖ Summary:\n",
    "MLflow eliminates the guesswork, version confusion, and manual tracking that slow down trustworthy ML development.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
